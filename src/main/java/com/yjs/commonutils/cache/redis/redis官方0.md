1 用Redis编程
Redis实现的命令的完整列表，以及每个命令的详尽文档。
流水线：了解如何一次发送多个命令，以节省往返时间。
Redis发布/订阅：Redis是一个快速，稳定的发布/订阅消息传递系统！一探究竟。
Redis Lua脚本编制：Redis Lua脚本编制功能文档。
调试Lua脚本：Redis 3.2引入了用于Redis脚本的本地Lua调试器。
内存优化：了解Redis如何使用RAM并学习一些技巧以减少使用RAM。
过期：Redis允许为每个密钥设置不同的生存时间，以便密钥过期后会自动将其从服务器中删除。
Redis作为LRU缓存：如何配置和使用Redis作为具有固定内存量和自动退出键的缓存。
Redis事务：可以将命令分组在一起，以便将它们作为单个事务执行。
大量插入数据：如何在短时间内向Redis实例添加大量现有或生成的数据。
分区：如何在多个Redis实例之间分配数据。
分布式锁：使用Redis实现分布式锁管理器。
Redis键空间通知：通过Pub / Sub（Redis 2.8或更高版本）获取键空间事件的通知。
使用Redis 创建二级索引：使用Redis数据结构创建二级索引，组合索引和遍历图。

1.0 redis命令
...

1.1 Redis管道
该时间称为RTT（往返时间）。很容易看到，当客户端需要连续执行许多请求时（例如，将多个元素添加到同一列表中，或使用许多键填充数据库），这会如何影响性能。例如，如果RTT时间为250毫秒（在Internet上的链接非常慢的情况下），即使服务器每秒能够处理10万个请求，我们每秒最多可以处理四个请求。

可以实现请求/响应服务器，以便即使客户端尚未读取旧响应，它也可以处理新请求。这样，可以将多个命令发送到服务器，而根本不需要等待答复，最后一步即可读取答复。

这称为流水线，并且是数十年来广泛使用的技术。例如，许多POP3协议实现已支持此功能，从而大大加快了从服务器下载新电子邮件的过程。

重要说明：当客户端使用流水线发送命令时，服务器将被迫使用内存将答复排队。因此，如果您需要使用流水线发送大量命令，则最好以具有合理数量的批处理方式发送它们，例如10k命令，阅读答复，然后再次发送10k命令，依此类推。速度几乎相同，但是所使用的额外内存将最大为将这10k命令的答复排队所需的最大数量。

流水线传输不仅是一种减少往返时间的延迟成本的方法，它实际上还可以极大地提高您在给定的Redis服务器中每秒可以执行的总操作量。


1.2 发布/订阅
推送消息的格式
消息是具有三个元素的数组回复。

第一个元素是消息的种类：

subscribe：表示我们已成功订阅了作为回复中第二个元素的频道。第三个参数表示我们当前订阅的频道数。

unsubscribe：表示我们已成功取消订阅作为回复中第二个元素的频道。第三个参数表示我们当前订阅的频道数。当最后一个参数为零时，我们将不再订阅任何频道，并且由于我们不在发布/订阅状态，因此客户端可以发出任何类型的Redis命令。

message：这是由于另一个客户端发出的PUBLISH命令而收到的消息。第二个元素是始发通道的名称，第三个参数是实际的消息有效负载。

数据库和作用域
发布/订阅与密钥空间无关。使其在任何级别（包括数据库编号）都不会受到干扰。

在db 10上发布，将由db 1上的订阅者听到。

如果您需要某种范围，请在通道前面加上环境名称（测试，暂存，生产等）。



模式匹配订阅
Redis Pub / Sub实现支持模式匹配。客户端可以订阅glob样式的模式，以便接收发送到与给定模式匹配的频道名称的所有消息。

例如：

PSUBSCRIBE news.*
将接收所有发送到信道消息news.art.figurative， news.music.jazz等所有的glob风格模式是有效的，那么多支持通配符。

PUNSUBSCRIBE news.*
然后将取消订阅该模式的客户。此呼叫不会影响其他订阅。

由于模式匹配而收到的消息以不同的格式发送：

消息的类型是pmessage：它是由另一个客户端发出的，与模式匹配预订匹配的PUBLISH命令的结果而接收到的消息。第二个元素是匹配的原始模式，第三个元素是始发通道的名称，最后一个元素是实际的消息有效负载。

1.3 lua脚本及调试

EVAL和EVALSHA



1.4 内存优化



尽可能使用哈希
小哈希被编码在很小的空间中，因此您应尽可能使用哈希来表示数据。例如，如果您在Web应用程序中具有表示用户的对象，而不是对名称，姓氏，电子邮件，密码使用不同的键，请对所有必填字段使用单个哈希。

如果您想进一步了解这一点，请阅读下一节。

使用哈希在Redis上抽象出非常高效的内存普通键值存储
我知道本节的标题有点吓人，但是我将详细解释这是什么意思。

基本上，可以使用Redis对纯键值存储进行建模，其中值仅可以是字符串，这不仅比Redis纯键具有更高的内存效率，而且还比Memcached高得多。

让我们从一个事实开始：几个键比包含一个带有几个字段的哈希的单个键使用更多的内存。这怎么可能？我们使用技巧。从理论上讲，为了保证我们在恒定时间内执行查询（在大O表示法中也称为O（1）），有必要在平均情况下使用具有恒定时间复杂度的数据结构，例如哈希表。

但是很多时候，哈希仅包含几个字段。当散列很小时，我们可以将其编码为O（N）数据结构，例如带有长度前缀键值对的线性数组。由于我们仅在N较小时执行此操作，因此HGET和HSET命令的摊销时间仍为O（1）：一旦包含的元素数量太大，哈希将转换为真实的哈希表（您可以在redis.conf中配置限制）。

这不仅从时间复杂度的角度来看效果很好，而且从固定时间的角度来看效果也不错，因为键值对的线性数组恰好可以很好地与CPU缓存配合使用（它具有更好的缓存位置比哈希表）。

但是，由于哈希字段和值不会（始终）表示为功能齐全的Redis对象，因此哈希字段不能像真实键一样具有关联的生存时间（到期），并且只能包含字符串。但是我们对此表示同意，无论如何，这是设计哈希数据类型API时的意图（我们比功能更信任简单性，因此不允许嵌套数据结构，因为不允许单个字段过期）。

因此，哈希可以提高内存效率。当存在一组相关字段时，使用散列表示对象或为其他问题建模时，这非常有用。但是，如果我们有一个简单的键值业务呢？

想象一下，我们想将Redis用作许多小对象的缓存，这些对象可以是JSON编码的对象，小HTML片段，简单键->布尔值等等。基本上任何东西都是字符串->带有小键和值的字符串映射。

现在，我们假设要缓存的对象已编号，例如：

对象：102393
对象：1234
对象：5
这就是我们所能做的。每次执行SET操作以设置新值时，我们实际上将密钥分为两部分，一部分用作密钥，另一部分用作哈希的字段名称。例如，名为“ object：1234”的对象实际上分为：

一个Key命名对象：12
一个名为34的字段
因此，我们使用除最后两个字符以外的所有字符作为键，并使用最后两个字符作为哈希字段名称。要设置密钥，我们使用以下命令：

HSET object:12 34 somevalue
如您所见，每个哈希将包含100个字段，这是CPU和内存节省之间的最佳折衷方案。

需要注意的另一件事是非常重要的，在这种模式下，每个哈希将具有或多或少的100个字段，而不管我们缓存的对象数量如何。这是因为我们的对象将始终以数字结尾，而不是随机字符串。在某种程度上，最终数量可以视为隐式预分片的一种形式。

小数字呢？喜欢对象：2？我们仅使用“ object：”作为键名，并使用整数作为哈希字段名来处理这种情况。因此object：2和object：10都将在键“ object：”内结束，但是其中一个作为字段名称“ 2”，另一个作为“ 10”。

这样可以节省多少内存？

我使用以下Ruby程序来测试其工作原理：

require 'rubygems'
require 'redis'

UseOptimization = true

def hash_get_key_field(key)
    s = key.split(":")
    if s[1].length > 2
        {:key => s[0]+":"+s[1][0..-3], :field => s[1][-2..-1]}
    else
        {:key => s[0]+":", :field => s[1]}
    end
end

def hash_set(r,key,value)
    kf = hash_get_key_field(key)
    r.hset(kf[:key],kf[:field],value)
end

def hash_get(r,key,value)
    kf = hash_get_key_field(key)
    r.hget(kf[:key],kf[:field],value)
end

r = Redis.new
(0..100000).each{|id|
    key = "object:#{id}"
    if UseOptimization
        hash_set(r,key,"val")
    else
        r.set(key,"val")
    end
}
这是针对Redis 2.2的64位实例的结果：

UseOptimization设置为true：1.7 MB已用内存
UseOptimization设置为false；11 MB的已用内存
这是一个数量级，我认为这使Redis或多或少地是那里存储效率最高的普通键值存储。

警告：要使此方法起作用，请确保在您的redis.conf中具有以下内容：

hash-max-zipmap-entries 256
还要记住，请根据您的键和值的最大大小设置以下字段：

hash-max-zipmap-value 1024
每当哈希超过指定的元素数或元素大小时，它将被转换为真实的哈希表，并且节省的内存将丢失。

您可能会问，为什么不在常规密钥空间中隐式地执行此操作，这样我就不必在乎了？原因有两个：一是我们倾向于明确权衡取舍，而这是许多因素之间的明显取舍：CPU，内存，最大元素大小。第二个问题是顶级密钥空间必须支持很多有趣的事情，例如过期，LRU数据等等，因此以一般方式执行此操作不切实际。

但是，Redis方式是用户必须了解事物的工作方式，以便能够选择最佳的折衷方案，并了解系统的确切行为。


1.5 过期



Redis如何过期密钥
Redis密钥以两种方式过期：被动方式和主动方式。

仅当某些客户端尝试访问密钥时，密钥才会被动失效，并且发现该密钥超时。

当然，这还不够，因为有过期的密钥将永远不会再次访问。这些密钥无论如何都应该过期，因此，Redis会定期对具有过期集的密钥中的一些密钥进行随机测试。从密钥空间中删除所有已过期的密钥。

具体来说，这是Redis每秒执行10次的操作：

从一组相关联的过期密钥中测试20个随机密钥。
删除找到的所有密钥已过期。
如果超过25％的密钥已过期，请从步骤1重新开始。
这是一个微不足道的概率算法，基本上是假设我们的样本可以代表整个密钥空间，并且我们会继续过期，直到可能过期的密钥百分比低于25％

这意味着在任何给定时刻，正在使用内存的已过期密钥的最大数量最大等于每秒最大写操作数量除以4。

复制链接和AOF文件中如何处理过期
为了在不牺牲一致性的情况下获得正确的行为，当密钥过期时，将在AOF文件中合成DEL操作并获得所有附加的副本节点。这样，到期过程就集中在主实例中，并且不会出现一致性错误。

但是，尽管连接到主数据库的副本不会独立使密钥失效（而是等待来自主数据库的DEL），但它们仍将处于数据集中存在的到期的完整状态，因此当选择副本作为主数据库时它将能够独立使密钥失效，从而完全充当主密钥。



1.6 将Redis用作LRU缓存(4.0.版本有新的LFU)



Maxmemory配置指令


使用maxmemory配置指令是为了将Redis配置为对数据集使用指定的内存量。可以使用redis.conf文件来设置配置指令，或者稍后在运行时使用CONFIG SET命令来设置。

例如，为了配置100 MB的内存限制，可以在redis.conf文件内部使用以下指令。

maxmemory 100mb
设置maxmemory为零将导致没有内存限制。这是64位系统的默认行为，而32位系统使用3GB的隐式内存限制。

当达到指定的内存量时，可以在不同的行为之间进行选择，这称为策略。Redis只会为可能导致使用更多内存的命令返回错误，或者它可以逐出某些旧数据，以便在每次添加新数据时返回到指定的限制。

驱逐政策
maxmemory使用maxmemory-policy配置指令配置达到限制时，会发生确切的行为Redis 。

可以使用以下策略：

noeviction：在达到内存限制并且客户端尝试执行可能导致使用更多内存的命令时返回错误（大多数写入命令，但是DEL和一些其他异常）。
allkeys-lru：通过尝试先删除较新使用的（LRU）键来退出键，以便为添加的新数据腾出空间。
volatile-lru：通过尝试先删除较新使用的（LRU）密钥来退出密钥，但仅在已设置了expire set的密钥之间，以便为添加的新数据腾出空间。
allkeys-random：随机逐出密钥，以便为添加的新数据腾出空间。
volatile-random：随机逐出键，以便为添加的新数据腾出空间，但仅逐出设置了expire set的键。
volatile-ttl：逐出设置了expire的密钥，并尝试首先逐出具有较短生存时间（TTL）的密钥，以便为添加的新数据腾出空间。
该政策挥发性-LRU，挥发性随机和挥发性-TTL的行为很像noeviction如果没有钥匙驱逐匹配的先决条件。

选择正确的逐出策略很重要，具体取决于应用程序的访问模式，但是您可以在应用程序运行时在运行时重新配置该策略，并使用Redis INFO输出监视缓存未命中和命中的次数，以调整设置。 。

一般而言，根据经验：

当您希望请求的受欢迎程度呈幂律分布时，请使用allkeys-lru策略，也就是说，您希望访问元素的子集比其他元素访问更多。如果不确定，这是一个不错的选择。
如果您具有对所有密钥进行连续扫描的周期性访问，或者当您期望分布是统一的（所有元素以相同的概率被访问）时，请使用allkeys-random。
如果您希望能够在创建缓存对象时通过使用不同的TTL值向Redis提供有关哪些是到期的最佳候选者的提示，请使用volatile-ttl。
当您要使用单个实例进行缓存并拥有一组持久密钥时，volatile-lru和volatile-random策略主要有用。但是，通常最好运行两个Redis实例来解决此问题。

还值得注意的是，将密钥设置为过期会消耗内存，因此使用诸如allkeys-lru之类的策略会提高内存效率，因为无需为在内存压力下驱逐密钥设置过期。

驱逐过程如何进行
重要的是要了解驱逐过程的工作方式如下：

客户端运行新命令，从而添加更多数据。
Redis会检查内存使用情况，如果大于使用maxmemory限制，则会根据策略将键逐出。
执行新命令，依此类推。
因此，我们不断越过内存限制，然后越过该限制，然后逐出按键以在限制范围内返回，从而不断跨越该限制。

如果某条命令导致一段时间内使用了大量内存（例如将较大的交集存储到新键中），则内存限制可能会超出明显数量。

近似LRU算法
Redis LRU算法不是确切的实现。这意味着Redis无法选择最好的驱逐候选者，即过去访问最多的访问者。取而代之的是，它将尝试对LRU算法进行近似计算，方法是对少量密钥进行采样，然后从采样的密钥中驱出最好的（访问时间最长）密钥。

但是，自Redis 3.0起，对该算

新的LFU模式
从Redis 4.0开始，可以使用新的“ 最少使用”逐出模式。在某些情况下，此模式可能会更好地工作（提供更好的命中率/未命中率），因为使用LFU Redis会尝试跟踪物品的进入频率，因此，很少使用的物品会被驱逐，而经常使用的物品则机会更大。保留在内存中。

如果您认为在LRU，最近访问过但实际上几乎从未请求过的项目不会过期，因此风险在于驱逐将来有更高机会请求的钥匙。LFU没有这个问题，通常应该更好地适应不同的访问模式。

要配置LFU模式，可以使用以下策略：

volatile-lfu 使用具有到期集的密钥在近似LFU中进行驱逐。
allkeys-lfu 使用近似的LFU退出任何密​​钥。
LFU近似于LRU：它使用一个概率计数器（称为莫里斯计数器），以便仅使用每个对象几个位来估计对象访问频率，并结合一个衰减周期，以便使计数器随时间减少：在某个时候，我们甚至不再希望将密钥视为过去经常访问的密钥，因此该算法可以适应访问模式的转变。

这些信息的采样方式与LRU发生的情况类似（如本文档前面的部分所述），以便选择驱逐候选人。

但是，与LRU不同，LFU具有某些可调参数：例如，如果频繁访问的项不再被访问，应该将其降低多快？还可以调整Morris计数器范围，以使算法更好地适应特定的用例。

默认情况下，Redis 4.0配置为：

在大约一百万个请求时使计数器饱和。
每隔一分钟使计数器衰减一次。
这些应该是合理的值，并且已经过实验测试，但是用户可能希望使用这些配置设置来选择最佳值。

有关如何调整这些参数的说明，可以redis.conf在源代码发行版的示例文件中找到，但简要地说，它们是：

lfu-log-factor 10
lfu-decay-time 1
衰减时间是显而易见的时间，它是在采样时发现计数器早于该值应衰减的分钟数。平均值的一个特殊值0：每次扫描时总是使计数器衰减，并且很少有用。

计数器对数因子会更改要使频率计数器达到饱和所需的命中次数，频率计数器刚好在0-255的范围内。因数越高，为了达到最大值需要更多的访问。根据下表，系数越低，计数器的分辨率越低，分辨率越高：

+--------+------------+------------+------------+------------+------------+
| factor | 100 hits   | 1000 hits  | 100K hits  | 1M hits    | 10M hits   |
+--------+------------+------------+------------+------------+------------+
| 0      | 104        | 255        | 255        | 255        | 255        |
+--------+------------+------------+------------+------------+------------+
| 1      | 18         | 49         | 255        | 255        | 255        |
+--------+------------+------------+------------+------------+------------+
| 10     | 10         | 18         | 142        | 255        | 255        |
+--------+------------+------------+------------+------------+------------+
| 100    | 8          | 11         | 49         | 143        | 255        |
+--------+------------+------------+------------+------------+------------+
因此，基本上，因素是要在具有较低访问权限的更好区分项与具有较高访问权限的区分项之间进行权衡。示例redis.conf文件自我记录注释中提供了更多信息。



由于LFU是一项新功能，因此与LRU相比，我们将很感谢您提供有关其在用例中的性能的反馈。



1.7 事务



MULTI，EXEC，DISCARD和WATCH是Redis中事务的基础。它们允许一步执行一组命令，并具有两个重要保证：



事务中的所有命令都被序列化并顺序执行。在 Redis事务的执行过程中，永远不会发生另一个客户端发出的请求。这样可以确保将命令作为单个隔离操作执行。

所有命令都将被处理，否则将不被处理，因此Redis事务也是原子的。在EXEC命令触发事务中的所有命令的执行，因此，如果客户失去了在事务的上下文中的服务器的连接调用之前EXEC操作的命令没有被执行，而不是如果EXEC命令被调用时，所有操作均已执行。使用 仅附加文件时Redis确保使用单个write（2）系统调用将事务写入磁盘。但是，如果Redis服务器崩溃或被系统管理员以某种困难的方式杀死，则可能仅注册了部分操作。Redis将在重新启动时检测到这种情况，并且将退出并显示错误。使用该redis-check-aof工具可以修复仅附加文件，该文件将删除部分事务，以便服务器可以再次启动。

从版本2.2开始，Redis以乐观锁定的形式对上述两个方面提供额外保证，其方式与检查和设置（CAS）操作非常相似。这将在此页面的稍后部分进行记录。

为什么Redis不支持回滚？
如果您具有关系数据库背景，则Redis命令在事务期间可能会失败，但Redis仍将执行事务的其余部分而不是回滚，这一事实对您来说可能很奇怪。

但是，对于此行为有好的意见：

仅当使用错误的语法（并且在命令队列期间无法检测到该问题）或针对持有错误数据类型的键调用Redis命令时，该命令才能失败：这实际上意味着失败的命令是编程错误的结果，还有一种很可能在开发过程中而不是生产过程中发现的错误。
Redis在内部得到了简化和更快，因为它不需要回滚的能力。


反对Redis的观点是发生错误，但是应该指出的是，通常回滚并不能使您免于编程错误。例如，如果查询将键增加2而不是1，或者将错误的键增加，则回滚机制将无济于事。鉴于没有人可以挽救程序员免受错误的影响，并且Redis命令失败所需的错误类型不太可能进入生产环境，因此我们选择了不支持错误回滚的更简单，更快速的方法。



1.8 Redis大量插入



使用协议，卢克


由于以下几个原因，使用普通的Redis客户端执行批量插入并不是一个好主意：在一个命令之后发送一个命令的幼稚方法很慢，因为您必须为每个命令的往返时间付费。可以使用流水线操作，但是要大量插入许多记录，您需要在阅读答复的同时编写新命令，以确保尽快插入。

只有一小部分客户端支持非阻塞I / O，并且并非所有客户端都能够以有效的方式解析答复以最大化吞吐量。出于所有这些原因，将数据批量导入Redis的首选方法是生成包含Redis协议（原始格式）的文本文件，以便调用插入所需数据所需的命令。

例如，如果我需要生成一个大型数据集，其中包含数十亿个键，格式为：“ keyN-> ValueN”，我将创建一个文件，其中包含以下Redis协议格式的命令：

SET Key0 Value0
SET Key1 Value1
...
SET KeyN ValueN
创建此文件后，剩下的动作是将其尽快送入Redis。过去，执行此操作的方法是将netcatwith与以下命令配合使用 ：

(cat data.txt; sleep 10) | nc localhost 6379 > /dev/null
但是，这不是执行批量导入的可靠方法，因为netcat并不真正知道何时传输所有数据，也无法检查错误。在2.6或更高版本的Redis中，该redis-cli实用程序支持一种称为管道模式的新模式，该模式旨在执行批量插入。



使用管道模式，运行的命令如下所示：



cat data.txt | redis-cli --pipe


这将产生类似于以下的输出：



All data transferred. Waiting for the last reply...
Last reply received from server.
errors: 0, replies: 1000000
redis-cli实用程序还将确保仅将从Redis实例收到的错误重定向到标准输出。

生成Redis协议
Redis协议的生成和解析非常简单，并 在此处记录。但是，为了生成用于批量插入目标的协议，您不需要了解协议的每个细节，而只需以以下方式表示每个命令即可：

*<args><cr><lf>
$<len><cr><lf>
<arg0><cr><lf>
<arg1><cr><lf>
...
<argN><cr><lf>
其中<cr>表示“ \ r”（或ASCII字符13），<lf>表示“ \ n”（或ASCII字符10）。

例如，命令SET键值由以下协议表示：

*3<cr><lf>
$3<cr><lf>
SET<cr><lf>
$3<cr><lf>
key<cr><lf>
$5<cr><lf>
value<cr><lf>
或表示为带引号的字符串：

"*3\r\n$3\r\nSET\r\n$3\r\nkey\r\n$5\r\nvalue\r\n"
您需要为批量插入生成的文件仅由以上述方式表示的命令组成，一个接一个。

以下Ruby函数生成有效的协议：

def gen_redis_proto(*cmd)
    proto = ""
    proto << "*"+cmd.length.to_s+"\r\n"
    cmd.each{|arg|
        proto << "$"+arg.to_s.bytesize.to_s+"\r\n"
        proto << arg.to_s+"\r\n"
    }
    proto
end

puts gen_redis_proto("SET","mykey","Hello World!").inspect
使用上述功能，可以使用以下程序在上述示例中轻松生成键值对：

(0...1000).each{|n|
    STDOUT.write(gen_redis_proto("SET","Key#{n}","Value#{n}"))
}
我们可以在通往redis-cli的管道中直接运行该程序，以执行我们的第一个批量导入会话。

$ ruby proto.rb | redis-cli --pipe
All data transferred. Waiting for the last reply...
Last reply received from server.
errors: 0, replies: 1000
管道模式在引擎盖下如何工作
redis-cli的管道模式内部所需的魔术要与netcat一样快，并且仍然能够理解服务器何时同时发送了最后一个答复。

这是通过以下方式获得的：

redis-cli --pipe尝试将数据尽快发送到服务器。
同时，它在可用时读取数据，尝试对其进行解析。
一旦没有更多数据可以从stdin中读取，它将发送一个特殊的ECHO命令，该命令带有一个随机的20个字节的字符串：我们确定这是最新发送的命令，并且我们确定如果我们收到相同的20个消息，我们可以匹配答复检查个字节作为批量回复。
一旦发送了此特殊的最终命令，接收代码的应答将开始与这20个字节的应答进行匹配。达到匹配的答复后，可以成功退出。
使用此技巧，我们不需要解析我们发送到服务器的协议就可以了解我们要发送多少命令，而只需了解答复即可。



但是，在解析答复时，我们会对所有已解析的答复进行计数，以便最后我们能够告诉用户通过大容量插入会话传输到服务器的命令数量。



1.9 分区：如何在多个Redis实例之间拆分数据



为什么分区有用
在Redis中进行分区有两个主要目标：

它允许使用许多计算机的内存总和来创建更大的数据库。如果不进行分区，则只能使用一台计算机可以支持的内存量。
它允许将计算能力扩展到多核和多台计算机，并将网络带宽扩展到多台计算机和网络适配器。
分区：如何在多个Redis实例之间拆分数据。
分区是将数据拆分为多个Redis实例的过程，因此每个实例将只包含键的一个子集。本文档的第一部分将向您介绍分区的概念，第二部分将向您展示Redis分区的替代方法。

为什么分区有用
在Redis中进行分区有两个主要目标：

它允许使用许多计算机的内存总和来创建更大的数据库。如果不进行分区，则只能使用一台计算机可以支持的内存量。
它允许将计算能力扩展到多核和多台计算机，并将网络带宽扩展到多台计算机和网络适配器。
分区基础
有不同的分区标准。想象一下，我们有四个Redis实例R0，R1，R2，R3和许多代表用户的键user:1，例如user:2，，...等，我们可以找到不同的方式来选择在哪个实例中存储给定的键。换句话说，存在将给定密钥映射到给定Redis服务器的不同系统。

执行分区的最简单方法之一是范围分区，它是通过将对象范围映射到特定的Redis实例中来实现的。例如，我可以说从ID 0到ID 10000的用户将进入实例R0，而从ID 10001到ID 20000的用户将进入实例R1，依此类推。

该系统可以正常工作并在实践中实际使用，但是它的缺点是需要一个将范围映射到实例的表。需要管理该表，并且每种对象都需要一个表，因此Redis中的范围分区通常是不可取的，因为它比其他替代分区方法效率低得多。

范围分区的替代方法是哈希分区。此方案适用于任何密钥，而无需使用形式的密钥object_name:<id>，并且非常简单：

获取密钥名称并使用哈希函数（例如，crc32哈希函数）将其转换为数字。例如，如果键为foobar，crc32(foobar)将输出类似的信息93024922。
对这个数字使用取模运算，以便将其转换为0到3之间的数字，以便可以将此数字映射到我的四个Redis实例之一。93024922 modulo 4等于2，所以我知道我的密钥foobar应该存储到R2实例中。注意：模运算返回除法运算的余数，并%以多种编程语言与运算符一起实现。
还有许多其他方法可以执行分区，但是通过这两个示例，您应该会明白。哈希分区的一种高级形式称为一致性哈希，由一些Redis客户端和代理实现。

分区的不同实现
分区可能是软件堆栈中不同部分的责任。

客户端分区意味着客户端直接选择在哪个节点上写入或读取给定密钥。许多Redis客户端实现客户端分区。
代理辅助分区意味着我们的客户将请求发送到能够使用Redis协议的代理，而不是直接将请求发送到正确的Redis实例。代理将确保根据配置的分区架构将请求转发到正确的Redis实例，并将答复发送回客户端。Redis和Memcached代理Twemproxy实现了代理辅助分区。
查询路由意味着您可以将查询发送到随机实例，该实例将确保将查询转发到正确的节点。Redis Cluster在客户端的帮助下实现了混合形式的查询路由（请求不会从Redis实例直接转发到另一个实例，而是会将客户端重定向到正确的节点）。
分区的缺点
Redis的某些功能在分区中不能很好地发挥作用：

通常不支持涉及多个键的操作。例如，如果两个集合存储在映射到不同Redis实例的键中，则无法执行它们之间的相交（实际上有方法可以执行此操作，但不能直接执行）。
不能使用涉及多个密钥的Redis事务。
分区粒度是关键，因此无法使用单个大键（如非常大的排序集）对数据集进行分片。
使用分区时，数据处理会更加复杂，例如，您必须处理多个RDB / AOF文件，并且要备份数据，则需要从多个实例和主机聚合持久性文件。
添加和删​​除容量可能很复杂。例如，Redis Cluster支持大多数透明的数据重新平衡，并具有在运行时添加和删除节点的能力，但是其他系统（例如客户端分区和代理）不支持此功能。但是，在这方面，一种称为预分片的技术会有所帮助。
数据存储还是缓存？
尽管无论将Redis用作数据存储还是用作缓存，Redis中的分区在概念上都是相同的，但是将其用作数据存储时存在很大的限制。当Redis用作数据存储时，给定的密钥必须始终映射到相同的Redis实例。当Redis用作缓存时，如果给定的节点不可用，则使用另一个节点并不是什么大问题，因为我们希望提高系统的可用性（即系统来回复我们的查询）。

如果给定密钥的首选节点不可用，一致性哈希实现通常可以切换到其他节点。同样，如果添加新节点，则部分新密钥将开始存储在新节点上。

这里的主要概念如下：

如果将Redis用作缓存，则使用一致的散列就可以进行向上和向下缩放。
如果将Redis用作存储，则使用固定的键到节点映射，因此节点数必须是固定的并且不能变化。否则，需要一个能够在添加或删除节点时在节点之间重新平衡键的系统，并且目前只有Redis Cluster能够做到这一点-Redis Cluster 于2015年4月1日全面可用并投入生产。
预分片
我们了解到分区的问题是，除非我们将Redis用作缓存，否则添加和删除节点可能很棘手，并且使用固定的key-instances映射要简单得多。

但是，数据存储需求可能会随时间变化。今天，我可以使用10个Redis节点（实例），但是明天我可能需要50个节点。

由于Redis的占地面积非常小且重量轻（备用实例使用1 MB内存），因此解决此问题的一种简单方法是从头开始使用许多实例。即使仅从一台服务器启动，也可以决定从一开始就生活在分布式环境中，并使用分区在单个服务器上运行多个Redis实例。

您可以从一开始就将实例数量选择为很大。例如，对于大多数用户而言，32或64个实例可以解决问题，并将为增长​​提供足够的空间。

这样，随着数据存储需求的增加以及您需要更多的Redis服务器，您要做的就是将实例从一台服务器移动到另一台服务器。一旦添加了第一台其他服务器，您将需要将一半Redis实例从第一台服务器移动到第二台服务器，依此类推。

使用Redis复制，您将可以为用户减少停机时间或减少停机时间：

在新服务器中启动空实例。
移动将这些新实例配置为源实例的从属的数据。
停止您的客户。
使用新的服务器IP地址更新移动实例的配置。
将SLAVEOF NO ONE命令发送到新服务器中的从站。
使用新的更新配置重新启动客户端。
最后，关闭旧服务器中不再使用的实例。
Redis分区的实现
到目前为止，我们已经在理论上介绍了Redis分区，但是实践呢？您应该使用什么系统？

Redis集群
Redis Cluster是获得自动分片和高可用性的首选方法。自2015年4月1日起，该产品已全面上市并投入生产。您可以在“ 群集”教程中获得有关Redis群集的更多信息。

一旦Redis Cluster可用，并且如果兼容Redis Cluster的客户端可用于您的语言，则Redis Cluster将成为Redis分区的事实上的标准。

Redis Cluster是查询路由和客户端分区之间的混合体。



1.10 redis分布式锁


安全与活动保障
我们将仅使用三个属性来对设计建模，从我们的角度来看，这三个属性是有效使用分布式锁所需的最低保证。

安全特性：互斥。在任何给定时刻，只有一个客户端可以持有锁。
活力属性A：无死锁。最终，即使锁定资源的客户端崩溃或分区，也始终可以获得锁定。
活动性B：容错能力。只要大多数Redis节点都处于运行状态，客户端就可以获取和释放锁。
为什么基于故障转移的实现还不够
为了了解我们要改进的内容，让我们使用大多数基于Redis的分布式锁库分析当前的事务状态。

使用Redis锁定资源的最简单方法是在实例中创建密钥。密钥通常使用Redis过期功能在有限的生存时间内创建，因此最终将被释放（列表中的属性2）。当客户端需要释放资源时，它将删除密钥。

从表面上看，这很好，但是存在一个问题：这是我们架构中的单点故障。如果Redis主服务器宕机了怎么办？好吧，让我们添加一个奴隶！如果主服务器不可用，请使用它。不幸的是，这是不可行的。这样，我们无法实现互斥的安全属性，因为Redis复制是异步的。

此模型存在明显的竞争条件：

客户端A获取主服务器中的锁。
在将密钥写入传输到从机之前，主机崩溃。
奴隶晋升为主人。
客户端B获取对相同资源A的锁定，而该资源A已对其持有锁定。安全违规！
有时候，在特殊情况下（例如在故障期间），多个客户端可以同时持有锁是完全可以的。在这种情况下，您可以使用基于复制的解决方案。否则，我们建议实施本文档中描述的解决方案。

单个实例正确实施
在尝试克服上述单实例设置的限制之前，让我们检查一下在这种简单情况下如何正确执行此设置，因为这在不时存在竞争条件的应用程序中实际上是一个可行的解决方案，并且因为单个实例是我们将用于此处描述的分布式算法的基础。

要获取锁，必须遵循以下方法：

    SET resource_name my_random_value NX PX 30000
该命令仅在密钥不存在（NX选项）且到期时间为30000毫秒（PX选项）时设置密钥。密钥设置为“我的随机值”。此值在所有客户端和所有锁定请求中必须唯一。

基本上，使用随机值是为了以安全的方式释放锁，并且脚本会告诉Redis：仅当密钥存在且存储在密钥上的值恰好是我期望的值时，才删除该密钥。这是通过以下Lua脚本完成的：

if redis.call("get",KEYS[1]) == ARGV[1] then
    return redis.call("del",KEYS[1])
else
    return 0
end
为了避免删除另一个客户端创建的锁，这一点很重要。例如，一个客户端可能获取了该锁，在某些操作中被阻塞的时间超过了该锁的有效时间（密钥将过期的时间），然后又删除了某个其他客户端已经获取的锁。仅使用DEL是不安全的，因为一个客户端可能会删除另一个客户端的锁。使用上述脚本时，每个锁都由一个随机字符串“签名”，因此仅当该锁仍是客户端尝试将其删除的设置时，该锁才会被删除。

这个随机字符串应该是什么？我假设它是来自/ dev / urandom的20个字节，但是您可以找到更便宜的方法来使其足够独特以完成您的任务。例如，一个安全的选择是使用/ dev / urandom为RC4设置种子，并从中生成伪随机流。一个更简单的解决方案是结合使用unix时间和微秒级分辨率，并将其与客户端ID串联在一起，它不那么安全，但在大多数环境中可能可以完成任务。

我们将其用作生存的关键时间，称为“锁定有效时间”。它既是自动释放时间，又是客户端执行另一操作之前客户端可以再次获取锁而技术上不违反互斥保证的时间，该时间仅限于给定的时间范围从获得锁的那一刻起的时间。

因此，现在我们有了获取和释放锁的好方法。该系统基于由一个始终可用的单个实例组成的非分布式系统的推理是安全的。让我们将概念扩展到没有此类保证的分布式系统。

Redlock算法
在算法的分布式版本中，我们假设我们有N个Redis母版。这些节点是完全独立的，因此我们不使用复制或任何其他隐式协调系统。我们已经描述了如何在单个实例中安全地获取和释放锁。我们认为该算法将使用此方法在单个实例中获取和释放锁，这是理所当然的。在我们的示例中，我们将N = 5设置为一个合理的值，因此我们需要在不同的计算机或虚拟机上运行5个Redis主服务器，以确保它们将以大多数独立的方式发生故障。

为了获取锁，客户端执行以下操作：

它以毫秒为单位获取当前时间。
它尝试在所有N个实例中顺序使用所有实例中相同的键名和随机值来获取锁定。在第2步中，在每个实例中设置锁定时，客户端使用的超时时间小于总锁定自动释放时间，以便获取该超时时间。例如，如果自动释放时间为10秒，则超时时间可能在5到50毫秒之间。这样可以防止客户端长时间与处于故障状态的Redis节点通信时保持阻塞：如果一个实例不可用，我们应该尝试与下一个实例尽快通信。
客户端通过从当前时间中减去在步骤1中获得的时间戳，来计算获取锁所花费的时间。当且仅当客户端能够在大多数实例（至少3个）中获取锁时， ，并且获取锁所花费的总时间小于锁有效时间，则认为已获取锁。
如果获取了锁，则将其有效时间视为初始有效时间减去经过的时间，如步骤3中所计算。
如果客户端由于某种原因（无法锁定N / 2 + 1个实例或有效时间为负）而未能获得该锁，则它将尝试解锁所有实例（即使它认为不是该实例）能够锁定）。
算法是异步的吗？
该算法基于这样的假设：尽管各进程之间没有同步时钟，但每个进程中的本地时间仍然以大约相同的速率流动，并且与锁的自动释放时间相比，误差很小。这个假设与现实世界的计算机非常相似：每台计算机都有一个本地时钟，我们通常可以依靠不同的计算机来产生很小的时钟漂移。

在这一点上，我们需要更好地指定我们的互斥规则：只有在持有锁的客户端将在锁有效时间内（如步骤3中获得的）减去一定时间（仅几毫秒）的情况下终止工作，才能保证这一点。为了补偿进程之间的时钟漂移）。

有关需要限制时钟漂移的类似系统的更多信息，本文提供了有趣的参考：租约：一种用于分布式文件缓存一致性的有效容错机制。

重试失败
当客户端无法获取锁时，它应在随机延迟后重试，以尝试使试图同时获取同一资源的多个客户端不同步（这可能会导致大脑分裂的情况，其中没人胜）。同样，客户端在大多数Redis实例中尝试获取锁定的速度越快，出现裂脑情况（以及需要重试）的窗口就越小，因此理想情况下，客户端应尝试将SET命令发送到N个实例同时使用多路复用。

值得强调的是，对于未能获取大多数锁的客户端，尽快释放（部分）获取的锁有多么重要，这样就不必等待密钥到期才能再次获取锁（但是，如果发生网络分区，并且客户端不再能够与Redis实例进行通信，则在等待密钥到期时需要支付可用性损失）。

释放锁
释放锁很简单，只需在所有实例中释放锁，无论客户端是否认为它能够成功锁定给定实例。

安全论点
该算法安全吗？我们可以尝试了解在不同情况下会发生什么。

首先，让我们假设客户端能够在大多数实例中获取锁。所有实例都将包含一个具有相同生存时间的密钥。但是，密钥是在不同的时间设置的，因此密钥也会在不同的时间过期。但是，如果第一个密钥在时间T1（在与第一台服务器联系之前进行采样的时间）设置为最差，而最后一个密钥在时间T2（从最后一台服务器获得答复的时间）设置为最坏的话，集合中第一个过期的密钥至少存在一次MIN_VALIDITY=TTL-(T2-T1)-CLOCK_DRIFT。所有其他键都将在以后失效，因此我们确保至少在这次同时设置这些键。

在设置大多数键的过程中，另一个客户端将无法获取锁，因为如果已经存在N / 2 + 1个键，则N / 2 + 1 SET NX操作将无法成功。因此，如果获取了锁，则不可能同时重新获取它（违反互斥属性）。

但是，我们还要确保尝试同时获取锁的多个客户端不能同时成功。

如果客户端使用接近或大于锁定最大有效时间（基本上是我们用于SET的TTL）的时间锁定了大多数实例，它将认为锁定无效并将对实例进行解锁，因此我们只需要考虑客户端能够在小于有效时间的时间内锁定大多数实例的情况。在这种情况下，对于上面已经说明的参数，MIN_VALIDITY没有客户端应该能够重新获得该锁。因此，只有当大多数锁定时间大于TTL时间时，多个客户端才能同时锁定N / 2 + 1个实例（“时间”为步骤2的结尾），从而使锁定无效。

您是否能够提供正式的安全证明，指向相似的现有算法或发现错误？这将不胜感激。

活力论据
系统活动性基于三个主要功能：

自动释放锁定（因为密钥过期）：最终可以再次使用锁定键。
通常情况下，客户通常会在未获得锁或获得锁且工作终止时合作删除锁，这使得我们不必等待钥匙过期就可以重新获得锁。锁。
当客户端需要重试锁定时，它等待的时间要比获取大多数锁定所需的时间长得多，以便概率地使资源争用期间的脑裂情况变得不可能。
但是，我们在网络分区上支付的可用性费用等于TTL时间，因此，如果存在连续的分区，我们可以无限期地支付此费用。每当客户端获取锁并在能够删除该锁之前进行分区就发生这种情况。

基本上，如果有无限连续的网络分区，则系统可能会在无限长的时间内不可用。

性能，崩溃恢复和fsync
使用Redis作为锁定服务器的许多用户在获取和释放锁的延迟以及每秒可能执行的获取/释放操作数方面都需要高性能。为了满足此需求，与N个Redis服务器进行通信以减少延迟的策略肯定是多路复用（或穷人的多路复用，即将套接字置于非阻塞模式，发送所有命令，并读取所有命令）之后，假设客户端和每个实例之间的RTT相似）。

但是，如果我们要针对崩溃恢复系统模型，还需要考虑持久性。

基本上在这里看到问题，让我们假设我们完全没有持久性地配置Redis。客户端在5个实例中的3个实例中获取了锁。客户端能够获取锁的一个实例被重新启动，此时，我们又可以为同一资源锁定3个实例，而另一个客户端可以再次锁定它，这违反了锁的排他性的安全性。

如果启用AOF持久性，则情况将会大大改善。例如，我们可以通过发送SHUTDOWN并重新启动它来升级服务器。因为Redis过期是从语义上实现的，所以实际上在服务器关闭时时间仍在过去，所以我们的所有要求都很好。但是，只要它是干净关闭，一切都很好。停电呢？如果默认情况下将Redis配置为每秒在磁盘上进行fsync，则重启后可能会丢失我们的密钥。从理论上讲，如果要在遇到任何类型的实例重新启动时都保证锁定安全，则需要在持久性设置中始终启用fsync = always。反过来，这将完全破坏性能，使其达到传统上以安全方式实现分布式锁的CP系统的水平。

但是，事情总比乍看之下要好。基本上，只要实例在崩溃后重新启动，它就不再参与任何当前活动的锁，算法安全性就得以保留，以便实例重新启动时的当前活动锁集全部是通过锁定实例而不是实例来获得的。正在重新加入系统。

为保证这一点，我们只需要使一个实例在崩溃后至少不可用，而不是我们使用的最大TTL（即实例崩溃时存在的所有与锁有关的所有键）所需的时间。无效并自动释放。

即使没有任何可用的Redis持久性，使用延迟的重启也基本上可以实现安全性，但是请注意，这可能会导致可用性下降。例如，如果大多数实例崩溃，则系统将在全局范围内无法使用TTL（此处，全局范围表示在此期间根本没有资源可锁定）。

使算法更可靠：扩展锁
如果客户端执行的工作由小的步骤组成，则默认情况下可以使用较小的锁有效时间，并扩展实现锁扩展机制的算法。基本上，如果在计算过程中，当锁有效性接近低值时，客户端可以通过向所有扩展密钥TTL的实例发送Lua脚本（如果密钥存在且其值仍然是）来扩展锁定获取锁时客户端分配的随机值。

客户端应仅在能够将锁扩展到大多数实例中且在有效时间内将重新获得的锁视为已考虑（基本上，所使用的算法与获取锁时所使用的算法非常相似）。

但是，这不会从技术上改变算法，因此应限制最大的锁重新尝试获取次数，否则会违反活动性之一。


1.11 Redis密钥空间通知

默认情况下，键空间事件通知是禁用的，因为该功能虽然不太明智，但会占用一些CPU资源。使用notify-keyspace-eventsredis.conf或通过CONFIG SET启用通知。



1.12 使用Redis进行二级索引


使用Redis进行二级索引
Redis并不完全是键值存储，因为值可以是复杂的数据结构。但是，它具有一个外部键值外壳：在API级别，数据由键名称寻址。可以说，从本质上讲，Redis仅提供主键访问。但是，由于Redis是数据结构服务器，因此可以使用其功能来建立索引，以便创建各种索引，包括复合（多列）索引。

本文档说明了如何使用以下数据结构在Redis中创建索引：

排序集可按ID或其他数字字段创建二级索引。
具有字典范围的排序集，用于创建更高级的二级索引，复合索引和图形遍历索引。
用于创建随机索引的集。
用于创建简单的可迭代索引和最后N个项目索引的列表。
使用Redis实现和维护索引是一个高级主题，因此大多数需要对数据执行复杂查询的用户应了解，如果关系存储可以更好地为他们提供服务。但是，通常，尤其是在缓存方案中，非常需要将索引数据存储到Redis中，以便加快需要某种形式的索引才能执行的常见查询的速度。